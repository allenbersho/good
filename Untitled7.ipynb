{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNYIICv_iI-E",
        "outputId": "866eb85f-668c-4ca7-85e3-36fdbfd21b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_text_splitters in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.8)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.28)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.38.1-py3-none-any.whl (59.5 MB)\n",
            "     ---------------------------------------- 59.5/59.5 MB 9.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: pypdf in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.8.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.3.70)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.4.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.3.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (1.97.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
            "Collecting chromadb>=1.0.9\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
            "     --------------------------------------- 19.5/19.5 MB 17.7 MB/s eta 0:00:00\n",
            "Collecting aiofiles<25.0,>=22.0\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Collecting brotli>=1.1.0\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl (357 kB)\n",
            "     ------------------------------------- 357.3/357.3 kB 21.7 MB/s eta 0:00:00\n",
            "Collecting fastapi<1.0,>=0.115.2\n",
            "  Using cached fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
            "Collecting gradio-client==1.11.0\n",
            "  Downloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
            "     ------------------------------------- 324.5/324.5 kB 19.6 MB/s eta 0:00:00\n",
            "Collecting groovy~=0.1\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Collecting huggingface-hub>=0.28.1\n",
            "  Downloading huggingface_hub-0.33.5-py3-none-any.whl (515 kB)\n",
            "     ------------------------------------- 515.7/515.7 kB 15.8 MB/s eta 0:00:00\n",
            "Collecting jinja2<4.0\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Collecting markupsafe<4.0,>=2.0\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (25.0)\n",
            "Collecting pandas<3.0,>=1.0\n",
            "  Using cached pandas-2.3.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
            "Collecting pillow<12.0,>=8.0\n",
            "  Using cached pillow-11.3.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.11.7)\n",
            "Collecting pydub\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.18\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Collecting ruff>=0.9.3\n",
            "  Downloading ruff-0.12.5-py3-none-win_amd64.whl (12.9 MB)\n",
            "     --------------------------------------- 12.9/12.9 MB 16.8 MB/s eta 0:00:00\n",
            "Collecting safehttpx<0.2.0,>=0.1.6\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Collecting semantic-version~=2.0\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting starlette<1.0,>=0.40.0\n",
            "  Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
            "     ---------------------------------------- 73.0/73.0 kB 3.9 MB/s eta 0:00:00\n",
            "Collecting tomlkit<0.14.0,>=0.12.0\n",
            "  Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
            "Collecting typer<1.0,>=0.12\n",
            "  Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from gradio) (4.14.1)\n",
            "Collecting uvicorn>=0.14.0\n",
            "  Using cached uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "Collecting websockets<16.0,>=10.0\n",
            "  Downloading websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "     ------------------------------------- 176.8/176.8 kB 10.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting build>=1.0.3\n",
            "  Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Collecting pybase64>=1.4.1\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-win_amd64.whl (36 kB)\n",
            "Collecting posthog<6.0.0,>=2.4.0\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "     -------------------------------------- 105.4/105.4 kB 5.9 MB/s eta 0:00:00\n",
            "Collecting onnxruntime>=1.14.1\n",
            "  Using cached onnxruntime-1.22.1-cp311-cp311-win_amd64.whl (12.7 MB)\n",
            "Collecting opentelemetry-api>=1.2.0\n",
            "  Using cached opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0\n",
            "  Using cached opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
            "Collecting tokenizers>=0.13.2\n",
            "  Downloading tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
            "     ---------------------------------------- 2.5/2.5 MB 22.9 MB/s eta 0:00:00\n",
            "Collecting pypika>=0.48.9\n",
            "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting grpcio>=1.58.0\n",
            "  Using cached grpcio-1.73.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
            "Collecting bcrypt>=4.0.1\n",
            "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "Collecting kubernetes>=28.1.0\n",
            "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "Collecting mmh3>=4.0.1\n",
            "  Using cached mmh3-5.1.0-cp311-cp311-win_amd64.whl (41 kB)\n",
            "Collecting rich>=10.11.0\n",
            "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "     ---------------------------------------- 243.2/243.2 kB ? eta 0:00:00\n",
            "Collecting jsonschema>=4.19.0\n",
            "  Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Collecting tzdata>=2022.7\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Collecting click>=8.0.0\n",
            "  Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Collecting shellingham>=1.3.0\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting pyproject_hooks\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (0.4.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Collecting jsonschema-specifications>=2023.03.6\n",
            "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Collecting referencing>=0.28.4\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Collecting rpds-py>=0.7.1\n",
            "  Using cached rpds_py-0.26.0-cp311-cp311-win_amd64.whl (231 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
            "Collecting google-auth>=1.0.1\n",
            "  Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Collecting requests-oauthlib\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting oauthlib>=3.2.2\n",
            "  Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Collecting durationpy>=0.7\n",
            "  Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Collecting coloredlogs\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting flatbuffers\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-6.31.1-cp310-abi3-win_amd64.whl (435 kB)\n",
            "Collecting sympy\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0\n",
            "  Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting googleapis-common-protos~=1.57\n",
            "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-proto==1.35.0\n",
            "  Using cached opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.56b0\n",
            "  Using cached opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
            "Collecting backoff>=1.10.0\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Collecting httptools>=0.6.3\n",
            "  Using cached httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
            "Collecting watchfiles>=0.13\n",
            "  Using cached watchfiles-1.1.0-cp311-cp311-win_amd64.whl (292 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Collecting zipp>=3.20\n",
            "  Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting pyreadline3\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: pytz, pypika, pydub, mpmath, flatbuffers, durationpy, brotli, zipp, websockets, websocket-client, tzdata, tomlkit, sympy, shellingham, semantic-version, ruff, rpds-py, python-multipart, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, pillow, overrides, oauthlib, mmh3, mdurl, markupsafe, importlib-resources, httptools, grpcio, groovy, fsspec, filelock, ffmpy, click, cachetools, bcrypt, backoff, aiofiles, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, referencing, pyasn1-modules, posthog, pandas, opentelemetry-proto, markdown-it-py, jinja2, importlib-metadata, humanfriendly, huggingface-hub, googleapis-common-protos, build, tokenizers, safehttpx, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, gradio-client, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, jsonschema, opentelemetry-sdk, gradio, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain_chroma\n",
            "Successfully installed aiofiles-24.1.0 backoff-2.2.1 bcrypt-4.3.0 brotli-1.1.0 build-1.2.2.post1 cachetools-5.5.2 chromadb-1.0.15 click-8.2.1 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.116.1 ffmpy-0.6.1 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.7.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 gradio-5.38.1 gradio-client-1.11.0 groovy-0.1.2 grpcio-1.73.1 httptools-0.6.4 huggingface-hub-0.33.5 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 jinja2-3.1.6 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 kubernetes-33.1.0 langchain_chroma-0.2.5 markdown-it-py-3.0.0 markupsafe-3.0.2 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 oauthlib-3.3.1 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 pandas-2.3.1 pillow-11.3.0 posthog-5.4.0 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.1 pydub-0.25.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 python-multipart-0.0.20 pytz-2025.2 referencing-0.36.2 requests-oauthlib-2.0.0 rich-14.0.0 rpds-py-0.26.0 rsa-4.9.1 ruff-0.12.5 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.2 sympy-1.14.0 tokenizers-0.21.2 tomlkit-0.13.3 typer-0.16.0 tzdata-2025.2 uvicorn-0.35.0 watchfiles-1.1.0 websocket-client-1.8.0 websockets-15.0.1 zipp-3.23.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community langchain_text_splitters langchain_openai langchain_chroma gradio python-dotenv pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIcQruQK5KQH",
        "outputId": "7d1a1780-f1ba-4634-ecb8-799f27b2d1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
            "     -------------------------------------- 470.2/470.2 kB 5.9 MB/s eta 0:00:00\n",
            "Collecting transformers<5.0.0,>=4.41.0\n",
            "  Downloading transformers-4.53.3-py3-none-any.whl (10.8 MB)\n",
            "     --------------------------------------- 10.8/10.8 MB 22.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Collecting torch>=1.11.0\n",
            "  Using cached torch-2.7.1-cp311-cp311-win_amd64.whl (216.1 MB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.7.1-cp311-cp311-win_amd64.whl (8.9 MB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.16.0-cp311-cp311-win_amd64.whl (38.6 MB)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.33.5)\n",
            "Requirement already satisfied: Pillow in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Collecting networkx\n",
            "  Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\allen\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Collecting safetensors>=0.4.3\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Collecting joblib>=1.2.0\n",
            "  Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\allen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
            "Installing collected packages: threadpoolctl, scipy, safetensors, networkx, joblib, torch, scikit-learn, transformers, sentence-transformers\n",
            "Successfully installed joblib-1.5.1 networkx-3.5 safetensors-0.5.3 scikit-learn-1.7.1 scipy-1.16.0 sentence-transformers-5.0.0 threadpoolctl-3.6.0 torch-2.7.1 transformers-4.53.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uAjwwkO361F",
        "outputId": "6ff7dd29-fe77-4f21-f788-ff726a1653bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\allen\\AppData\\Local\\Temp\\ipykernel_4480\\1165889928.py:18: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings_model = HuggingFaceEmbeddings(\n",
            "c:\\Users\\allen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\allen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\allen\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded documents: 49\n",
            "Example doc content: UIN- BAJHLIP23020V012223                                 Global Health Care/ Policy Wordings/Page 1 \n",
            " \n",
            " \n",
            "Bajaj Allianz General Insurance Co. Ltd.                       \n",
            "Bajaj Allianz House, Airport Road, Yerawada, Pune - 411 006. Reg. No.: 113 \n",
            "For more details, log on to: www.bajajallianz.com | E-mail: bagichelp@bajajallianz.co.in or \n",
            "Call at: Sales - 1800 209 0144 / Service - 1800 209 5858 (Toll Free No.) \n",
            "Issuing Office: \n",
            " \n",
            "GLOBAL HEALTH CARE \n",
            " \n",
            " \n",
            "Policy Wordings \n",
            " \n",
            "UIN- BAJHLIP23020V012223 \n",
            "SECTION A) PREAMBLE \n",
            " \n",
            "Whereas the Insured described in the Policy Schedule hereto (hereinafter called the ‘Insured’  or “Policyholder” or \n",
            "“Insured Person”) has made to Bajaj Allianz General Insurance Company Limited (hereinafter called the “Company” \n",
            "or “Insurer” or “Insurance Company”) a proposal or Proposal as mentioned in the transcript of the Proposal, which \n",
            "shall be the basis of this Contract and is deemed to be incorporated herein, containing certain undertakings , \n",
            "declarations, information/particulars and statements, which is hereby agreed to be the basis of this Contract and be \n",
            "considered as incorporated herein, for the insurance Contract hereinafter contained and has paid the premium \n",
            "specified in the Policy Sche dule hereto as consideration for such insurance Contract, now the Company agrees, \n",
            "subject always to the Policy Schedule and the following terms, conditions, exclusions, and limitations of the Policy, \n",
            "and in excess of the amount of the Deductible/ Co-Payment, to indemnify the Insured in respect of an admissible \n",
            "claim in the manner and to the extent hereinafter stated. \n",
            " \n",
            "SECTION B) DEFINITIONS - STANDARD DEFINITIONS \n",
            "Words or terms mentioned below have the meaning ascribed to them wherever they appear in this Po licy, and \n",
            "references to the singular or to the masculine, include references to the plural or to the feminine wherever the context \n",
            "permits. If any word starts with Capital alphabet but is not defined in the Standard Definitions or Specific Definitions, \n",
            "then such word shall be interpreted as per the headings of the respective clauses/points in these Policy Wordings. \n",
            " \n",
            "1. Accident:- \n",
            "An Accident means sudden, unforeseen and involuntary event caused by external, visible and violent means. \n",
            " \n",
            "2. Any one Illness:- \n",
            "Any one Illness means continuous Period of Illness and it includes relapse within 45 days from the date of last \n",
            "consultation with the Hospital/Nursing Home where treatment was taken. \n",
            " \n",
            "3. AYUSH Hospital:- \n",
            "An AYUSH Hospital is a healthcare facility wherein medical/surgical/para-surgical treatment procedures and \n",
            "interventions are carried out by AYUSH Medical Practitioner(s) comprising of any of the following: \n",
            "a. Central or State Government AYUSH Hospital; or \n",
            "b. Teaching Hospital attached to AYUSH College recognized by the Central Government/Central Council of \n",
            "Indian Medicine/Central Council for Homeopathy; or \n",
            "c. AYUSH Hospital, standalone or co-located with Inpatient healthcare facility of any recognized system of \n",
            "medicine, registered with the local authorities, wherever applicable, and is under the supervision of a qualified \n",
            "registered AYUSH Medical Practitioner and must comply with all the following criterion: \n",
            "i. Having at least 5 Inpatient beds; \n",
            "ii. Having qualified AYUSH Medical Practitioner in charge round the clock; \n",
            "iii. Having dedicated AYUSH therapy sections as required and/or has equipped operation theatre where \n",
            "surgical procedures are to be carried out; \n",
            "iv.Maintaining daily records of the patients and making them accessible to the Insurance Company’s \n",
            "authorized representative. \n",
            " \n",
            "4. AYUSH Day Care Centre:- \n",
            "AYUSH Day Care Centre means and includes Community Health Centre (CHC), Primary Health Centre (PHC), \n",
            "Dispensary, Clinic, Polyclinic or any such health centre which is registered with the local authorities, wherever \n",
            "applicable and having facilities for carrying out treatment procedures and medical or surgical/para-surgical \n",
            "interventions or both under the supervision of registered AYUSH Medical Practitioner (s) on Day Care Treatment \n",
            "basis without Inpatient services and must comply with all the following criterion: \n",
            "i. Having qualified registered AYUSH Medical Practitioner(s) in charge; \n",
            "ii. Having dedicated AYUSH therapy sections as required and/or has equipped operation theatre where \n",
            "surgical procedures are to be carried out; \n",
            "iii. Maintaining daily records of the patients and making them accessible to the  Insurance Company’s \n",
            "authorized representative.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from uuid import uuid4\n",
        "\n",
        "# import the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# configuration\n",
        "DATA_PATH = r\"data\"\n",
        "CHROMA_PATH = r\"chroma_db\"\n",
        "\n",
        "# initiate the embeddings model\n",
        "# embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"BAAI/bge-small-en\",\n",
        "    model_kwargs={\"device\": \"cpu\"}  # or \"cuda\" if using GPU\n",
        ")\n",
        "\n",
        "# initiate the vector store\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=CHROMA_PATH,\n",
        ")\n",
        "\n",
        "# loading the PDF document\n",
        "loader = PyPDFDirectoryLoader(DATA_PATH)\n",
        "\n",
        "raw_documents = loader.load()\n",
        "\n",
        "# splitting the document\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# creating the chunks\n",
        "chunks = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "# creating unique ID's\n",
        "uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
        "\n",
        "# adding chunks to vector store\n",
        "vector_store.add_documents(documents=chunks, ids=uuids)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Loaded documents:\", len(raw_documents))\n",
        "print(\"Example doc content:\", raw_documents[0].page_content if raw_documents else \"No docs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "_Ea9sfVh8IMi",
        "outputId": "89d3c898-8de9-48a7-b300-e6daf1e0a41e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\allen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\allen\\AppData\\Local\\Temp\\ipykernel_19140\\3405665471.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\", model_kwargs={\"device\": \"cpu\"})\n",
            "C:\\Users\\allen\\AppData\\Local\\Temp\\ipykernel_19140\\3405665471.py:21: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
            "  llm = ChatOllama(model=\"mistral\", temperature=0.5)\n",
            "c:\\Users\\allen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "        You are a strict assistant who answers only based on the provided knowledge.\n",
            "        Your task is to:\n",
            "        1. First answer with \"Yes\" or \"No\" only.\n",
            "        2. Then, give a short reason (1-2 sentences) based on the knowledge.\n",
            "        3. If the knowledge does not contain enough information to answer, respond with \"I don't know based on the provided document.\"\n",
            "\n",
            "        Do not use any of your own knowledge.\n",
            "\n",
            "        The question: hi\n",
            "\n",
            "        Conversation history: []\n",
            "\n",
            "        The knowledge: with multiple platforms via which You can always reach out to Us at below mentioned touch points \n",
            "1. Our toll-free number 1-800-209- 5858 or 020-30305858, say Say “Hi” on WhatsApp on +91 7507245858\n",
            "\n",
            "Sl Item \n",
            "1 BABY CHARGES (UNLESS SPECIFIED/INDICATED)  \n",
            "2 HAND WASH \n",
            "3 SHOE COVER \n",
            "4 CAPS \n",
            "5 CRADLE CHARGES \n",
            "6 COMB \n",
            "7 EAU-DE-COLOGNE / ROOM FRESHNERS \n",
            "8 FOOT COVER \n",
            "9 GOWN \n",
            "10 SLIPPERS  \n",
            "11 TISSUE PAPER \n",
            "12 TOOTH PASTE \n",
            "13 TOOTH BRUSH \n",
            "14 BED PAN \n",
            "15 FACE MASK \n",
            "16 FLEXI MASK \n",
            "17 HAND HOLDER\n",
            "\n",
            "Sl Item \n",
            "1 BABY CHARGES (UNLESS SPECIFIED/INDICATED)  \n",
            "2 HAND WASH \n",
            "3 SHOE COVER \n",
            "4 CAPS \n",
            "5 CRADLE CHARGES \n",
            "6 COMB \n",
            "7 EAU-DE-COLOGNE / ROOM FRESHNERS \n",
            "8 FOOT COVER \n",
            "9 GOWN \n",
            "10 SLIPPERS  \n",
            "11 TISSUE PAPER \n",
            "12 TOOTH PASTE \n",
            "13 TOOTH BRUSH \n",
            "14 BED PAN \n",
            "15 FACE MASK \n",
            "16 FLEXI MASK \n",
            "17 HAND HOLDER\n",
            "\n",
            "problem on the phone, please email or write to Us:  \n",
            "[For designer Phone icon]  +353 1 630 1301 \n",
            "[For designer Email icon:]  client.services@allianzworldwidecare.com  \n",
            "[For designer Address Icon:]  Customer Advocacy Team, Allianz Care, 15 Joyce Way, Park West Business\n",
            "\n",
            "www.bajajallianz.com/about-Us/customer-service.html \n",
            "4. E-mail  \n",
            "a) Level 1 Write to bagichelp@bajajallianz.co.in and for senior citizens to seniorcitizen@bajajallianz.co.in \n",
            "b) Level 2 In case You are not satisfied with the response given to You at Level 1 You may write to Our\n",
            "\n",
            "\n",
            "        \n",
            "\n",
            "        You are a strict assistant who answers only based on the provided knowledge.\n",
            "        Your task is to:\n",
            "        1. First answer with \"Yes\" or \"No\" only.\n",
            "        2. Then, give a short reason (1-2 sentences) based on the knowledge.\n",
            "        3. If the knowledge does not contain enough information to answer, respond with \"I don't know based on the provided document.\"\n",
            "\n",
            "        Do not use any of your own knowledge.\n",
            "\n",
            "        The question: hi\n",
            "\n",
            "        Conversation history: []\n",
            "\n",
            "        The knowledge: with multiple platforms via which You can always reach out to Us at below mentioned touch points \n",
            "1. Our toll-free number 1-800-209- 5858 or 020-30305858, say Say “Hi” on WhatsApp on +91 7507245858\n",
            "\n",
            "Sl Item \n",
            "1 BABY CHARGES (UNLESS SPECIFIED/INDICATED)  \n",
            "2 HAND WASH \n",
            "3 SHOE COVER \n",
            "4 CAPS \n",
            "5 CRADLE CHARGES \n",
            "6 COMB \n",
            "7 EAU-DE-COLOGNE / ROOM FRESHNERS \n",
            "8 FOOT COVER \n",
            "9 GOWN \n",
            "10 SLIPPERS  \n",
            "11 TISSUE PAPER \n",
            "12 TOOTH PASTE \n",
            "13 TOOTH BRUSH \n",
            "14 BED PAN \n",
            "15 FACE MASK \n",
            "16 FLEXI MASK \n",
            "17 HAND HOLDER\n",
            "\n",
            "Sl Item \n",
            "1 BABY CHARGES (UNLESS SPECIFIED/INDICATED)  \n",
            "2 HAND WASH \n",
            "3 SHOE COVER \n",
            "4 CAPS \n",
            "5 CRADLE CHARGES \n",
            "6 COMB \n",
            "7 EAU-DE-COLOGNE / ROOM FRESHNERS \n",
            "8 FOOT COVER \n",
            "9 GOWN \n",
            "10 SLIPPERS  \n",
            "11 TISSUE PAPER \n",
            "12 TOOTH PASTE \n",
            "13 TOOTH BRUSH \n",
            "14 BED PAN \n",
            "15 FACE MASK \n",
            "16 FLEXI MASK \n",
            "17 HAND HOLDER\n",
            "\n",
            "problem on the phone, please email or write to Us:  \n",
            "[For designer Phone icon]  +353 1 630 1301 \n",
            "[For designer Email icon:]  client.services@allianzworldwidecare.com  \n",
            "[For designer Address Icon:]  Customer Advocacy Team, Allianz Care, 15 Joyce Way, Park West Business\n",
            "\n",
            "www.bajajallianz.com/about-Us/customer-service.html \n",
            "4. E-mail  \n",
            "a) Level 1 Write to bagichelp@bajajallianz.co.in and for senior citizens to seniorcitizen@bajajallianz.co.in \n",
            "b) Level 2 In case You are not satisfied with the response given to You at Level 1 You may write to Our\n",
            "\n",
            "\n",
            "        \n",
            "\n",
            "        You are a strict assistant who answers only based on the provided knowledge.\n",
            "        Your task is to:\n",
            "        1. First answer with \"Yes\" or \"No\" only.\n",
            "        2. Then, give a short reason (1-2 sentences) based on the knowledge.\n",
            "        3. If the knowledge does not contain enough information to answer, respond with \"I don't know based on the provided document.\"\n",
            "\n",
            "        Do not use any of your own knowledge.\n",
            "\n",
            "        The question: what is the policy \n",
            "\n",
            "        Conversation history: [['hi', ' Yes, you can reach out to them via email by writing to client.services@allianzworldwidecare.com based on the provided document.']]\n",
            "\n",
            "        The knowledge: expressed in this Policy.\n",
            "\n",
            "commencement of Policy Period or during the Policy Period.\n",
            "\n",
            "and conditions of the policy. If he/she is not satisfied with any of the terms and conditions, he/she has the option to cance l his/her \n",
            "policy. This option is available in case of policies with a term of one ye ar or more.\n",
            "\n",
            "and conditions of the policy. If he/she is not satisfied with any of the terms and conditions, he/she has the option to cance l his/her \n",
            "policy. This option is available in case of policies with a term of one ye ar or more.\n",
            "\n",
            "mentioned in the schedule. For claim serviced by the Company, the Policy related issues to be communicated to the Policy \n",
            "issuing office of the Company at the address mentioned in the schedule.\n",
            "\n",
            "\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_chroma import Chroma\n",
        "import gradio as gr\n",
        "\n",
        "# import the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# configuration\n",
        "DATA_PATH = r\"data\"\n",
        "CHROMA_PATH = r\"chroma_db\"\n",
        "\n",
        "# embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\", model_kwargs={\"device\": \"cpu\"})\n",
        "\n",
        "\n",
        "# initiate the model\n",
        "# llm = ChatOpenAI(temperature=0.5, model='gpt-4o-mini')\n",
        "llm = ChatOllama(model=\"mistral\", temperature=0.5)\n",
        "\n",
        "\n",
        "# connect to the chromadb\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings_model,\n",
        "    persist_directory=CHROMA_PATH,\n",
        ")\n",
        "\n",
        "# Set up the vectorstore to be the retriever\n",
        "num_results = 5\n",
        "retriever = vector_store.as_retriever(search_kwargs={'k': num_results})\n",
        "\n",
        "# call this function for every message added to the chatbot\n",
        "def stream_response(message, history):\n",
        "    #print(f\"Input: {message}. History: {history}\\n\")\n",
        "\n",
        "    # retrieve the relevant chunks based on the question asked\n",
        "    docs = retriever.invoke(message)\n",
        "\n",
        "    # add all the chunks to 'knowledge'\n",
        "    knowledge = \"\"\n",
        "\n",
        "    for doc in docs:\n",
        "        knowledge += doc.page_content+\"\\n\\n\"\n",
        "\n",
        "\n",
        "    # make the call to the LLM (including prompt)\n",
        "    if message is not None:\n",
        "\n",
        "        partial_message = \"\"\n",
        "\n",
        "        rag_prompt = f\"\"\"\n",
        "        You are a strict assistant who answers only based on the provided knowledge.\n",
        "        Your task is to:\n",
        "        1. First answer with \"Yes\" or \"No\" only.\n",
        "        2. Then, give a short reason (1-2 sentences) based on the knowledge.\n",
        "        3. If the knowledge does not contain enough information to answer, respond with \"I don't know based on the provided document.\"\n",
        "\n",
        "        Do not use any of your own knowledge.\n",
        "\n",
        "        The question: {message}\n",
        "\n",
        "        Conversation history: {history}\n",
        "\n",
        "        The knowledge: {knowledge}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        print(rag_prompt)\n",
        "\n",
        "        # stream the response to the Gradio App\n",
        "        for response in llm.stream(rag_prompt):\n",
        "            partial_message += response.content\n",
        "            yield partial_message\n",
        "\n",
        "# initiate the Gradio app\n",
        "chatbot = gr.ChatInterface(stream_response, textbox=gr.Textbox(placeholder=\"Send to the LLM...\",\n",
        "    container=False,\n",
        "    autoscroll=True,\n",
        "    scale=7),\n",
        ")\n",
        "\n",
        "# launch the Gradio app\n",
        "chatbot.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
